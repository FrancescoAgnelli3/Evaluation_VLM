Summary of `/home/uniusr03/projects/test_for_ft/answer_questions.py` and results comparison

1) What the code does
- Purpose: runs video-only VLM inference for a set of questions/videos and saves per-model answer logs under `results/`.
- Models supported: Cosmos-Reason1 (transformers), Cosmos-Reason2 (local utils + Qwen3VL), and Qwen3 via an OpenAI-compatible vLLM endpoint. Model selection is CLI-driven (`--model`), defaulting to Cosmos2-2B.
- Prompts: two prompt styles are executed per video:
  - `json_detailed`: strict JSON schema with explicit epistemic rules.
  - `no_json`: structured plain-text analysis instructions.
- Video input handling:
  - Cosmos1/Cosmos2: passes `{"type":"video","path":"..."}` to the processor; sampling is controlled via `--video-fps`/`--max-video-frames`.
  - Qwen: converts the video to a data URL and sends it as `video_url` to the OpenAI-compatible endpoint.
- Output format: each run writes a single `.txt` file per video/model in `results/` that includes prompt text, elapsed time, token usage (for Qwen), and the model’s raw response text for each prompt.

2) How it was built (from code structure and the “chat history” recorded in result files)
- The script is built around a “prompt + response log” format: each output file contains the exact prompt text and the model’s response. This is effectively a preserved chat history for each model/run (see any file in `results/`, e.g. `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_qwen_2B.txt`).
- The `PROMPTS` list in code shows the intended, current prompt wording and response format. However, some result files embed a different `json_detailed` prompt (older/alternate wording), which indicates the script or prompts have been iterated across runs. Example: `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_cosmos2_2B.txt` includes a different schema with `number_of_lanes` as a scalar and `lane_directions` as a list, which does not match the current `PROMPT_JSON_DETAILED` in code.
- The pipeline writes both `.txt` logs and separate JSON answer dumps (`results/*_answers.json`) that appear to follow a different schema (keys like `lanes_number`, `traffic_direction`, etc.), suggesting these were produced by an earlier version of the prompt or a different aggregation script.

3) Model comparison from `results/` (JSON validity, hallucination risk, bias signals)

3.1 JSON validity (json_detailed prompt)
- Parsed the `json_detailed` response blocks for all 17 files per model (total 85 files). Valid JSON rates:
  - qwen-2B: 17/17 valid JSON
  - qwen-8B: 17/17 valid JSON
  - cosmos2-8B: 13/17 valid JSON
  - cosmos2-2B: 10/17 valid JSON
  - cosmos1: 7/17 valid JSON
- Common invalid JSON issues:
  - Markdown code fences around JSON or malformed syntax. Example from cosmos1: `results/7_21__21_record_20251205_134501_00m35s_00m45s_poss_cosmos1.txt` starts with ```json and later contains syntax that fails JSON parsing.
  - Unterminated strings or structural inconsistencies. Example from cosmos2-2B: `results/15_9__9_record_20251209_194501_00m00s_00m10s_poss_cosmos2_2B.txt` shows malformed JSON (unterminated string).

3.2 Schema adherence and format drift
- Even when JSON is syntactically valid, some models drift from the requested schema in the prompt:
  - cosmos1 and cosmos2 responses sometimes omit required `visible`/`value`/`confidence` sub-objects, or replace objects with scalars. See `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_cosmos1.txt` where `traffic_status` uses `lane_id: 0` and `status` is a string, not an object.
  - The aggregated JSON files in `results/*_answers.json` use a different schema entirely (e.g., `lanes_number`, `traffic_direction`). Example: `results/qwen_2B_answers.json`.

3.3 No-json prompt compliance
- Qwen-2B has 3/17 cases where `no_json` responses are empty (no response text). Example: `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_qwen_2B.txt`.
- Qwen-8B often returns chain-of-thought-style reasoning and does not follow the requested structured bullet format. Example: `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_qwen_8B.txt` includes a long, conversational analysis and a `<think>` block before the requested headings.
- Cosmos2-2B’s `no_json` answers tend to follow the headings and sentence format more closely in the sampled file above, though content accuracy still varies.

3.4 Hallucination and bias signals (examples and cross-model contradictions)
- The same clip yields materially different factual claims across models, suggesting hallucination risk or overconfidence:
  - In `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_qwen_2B.txt`, Qwen-2B reports no pedestrians and low risk, with specific signage claims like `speed_limit: 24` and `warning_signs: true`.
  - In `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_qwen_8B.txt`, Qwen-8B reports pedestrians “crossing in roadway,” an illegal stop, and a medium overall risk.
  - In `results/1_12__12_record_20251207_174501_00m42s_00m52s_poss_cosmos1.txt`, Cosmos1 reports red light violations and abrupt lane changes, plus a specific speed limit of 50.
- Because these outputs disagree on basic scene elements (pedestrians present, illegal stop, signage, speed limits), at least some of these details are likely hallucinated or overconfident guesses. The bias pattern here is that larger models (and some Cosmos outputs) tend to infer violations/risk factors even when smaller models report a low-risk scene.

3.5 Prompt style impact (old schema vs current schema, JSON format, hallucinations)
- The old prompt is terse and schema-locked: a single JSON object with strict keys, nulls for unknowns, and all string fields forced to be strings (or null). This style tends to suppress extra narration, but it can also invite "forced filling" where the model guesses a string value instead of using null. That effect shows up in the legacy aggregated outputs in `results/*_answers.json` (e.g., `results/qwen_2B_answers.json`) where fields like `traffic_direction` or `other_infrastructure` are filled with specific scene claims even though visibility is uncertain.
- The current `json_detailed` prompt adds explicit epistemic rules and confidence scores. This should, in theory, reduce hallucinations by allowing "unknown" with low confidence and by tying `traffic_status` to lane visibility. In practice, the results still show overconfident details (e.g., speed limits, specific violations) and cross-model contradictions. The extra structure does not fully prevent hallucinations, but it does make them easier to detect because the model must commit to a visible/unknown choice and provide confidence.
- JSON validity improved with Qwen in the current setup (17/17 valid JSON in the `json_detailed` blocks), likely helped by `response_format` on the OpenAI-compatible endpoint. Cosmos models still frequently wrap JSON in code fences or drift in schema, which undermines strict parsing even if the content is plausible.
- The schema mismatch across time (old prompt vs current prompt) is visible: `results/*_answers.json` uses keys like `lanes_number` and `traffic_direction`, whereas the current `json_detailed` prompt expects nested `visible/value/confidence` objects. This mismatch makes automated comparisons across runs harder and can mask hallucination trends if the parser expects the newer schema.

3.6 Risk evaluation case study: 16__16_record_20251209_101501_03m44s_03m54s_poss
- Known risk in this clip: one of the two people on the motorcycle is not wearing a helmet.
- json_detailed prompt outcomes (risk in JSON):
  - Qwen-2B reports low overall risk and no vehicle events; no helmet risk mentioned (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_qwen_2B.txt`).
  - Qwen-8B flags an illegal stop (motorcycle stopped on sidewalk) but still low overall risk; no helmet risk mentioned (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_qwen_8B.txt`).
  - Cosmos1 includes other vehicle-event text but does not mention helmet usage (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_cosmos1.txt`).
  - Cosmos2-2B and Cosmos2-8B list no vehicle events and do not mention helmet usage (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_cosmos2_2B.txt`, `results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_cosmos2_8B.txt`).
- no_json prompt outcomes (risk in text):
  - Qwen-2B says no risky situations and low risk; no helmet risk mentioned (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_qwen_2B.txt`).
  - Qwen-8B explicitly states the rider is wearing a helmet and concludes low risk, which contradicts the known risk (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_qwen_8B.txt`).
  - Cosmos1 focuses on navigating around a parked car and general caution, not helmet use (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_cosmos1.txt`).
  - Cosmos2-2B cites illegal scooter parking; Cosmos2-8B cites lane crossing and pedestrians in road; neither mentions helmet usage (`results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_cosmos2_2B.txt`, `results/5_16__16_record_20251209_101501_03m44s_03m54s_poss_cosmos2_8B.txt`).
- old prompt outcomes (legacy JSON in `results/*_answers.json`):
  - qwen_2B_answers.json: risks list only pedestrians walking in the street; no helmet risk (`results/qwen_2B_answers.json`).
  - cosmos2_2B_answers.json: verbose signage/infrastructure and pedestrian items, but no helmet-related risk (`results/cosmos2_2B_answers.json`).
  - cosmos2_8B_answers.json: empty risks list; no helmet risk (`results/cosmos2_8B_answers.json`).
  - cosmos_answers.json: risks list empty; no helmet risk (`results/cosmos_answers.json`).
- Gemini gold (results_gold teacher JSON):
  - `results_gold/16__16_record_20251209_101501_03m44s_03m54s_poss.teacher.json` reports overall risk = medium with risks tied to illegal parking, potential wrong-direction travel, and pedestrians in the roadway; no helmet-related risk is mentioned.
- Net result: none of the models/prompt styles surface the no-helmet risk; one model (Qwen-8B, no_json) incorrectly asserts helmet use, which is a direct miss of the risky situation.

4) Key takeaways
- The script is a multi-model, video-only VLM evaluation harness that writes rich “chat history” logs (prompts + responses) per video/model.
- JSON validity is strongest for Qwen-2B/8B and weaker for Cosmos models, which frequently include markdown or schema deviations.
- Non-JSON prompt compliance is inconsistent: Qwen-8B tends to ignore strict formatting and insert reasoning text; Qwen-2B sometimes returns empty responses.
- Cross-model disagreements in risk factors and signage details indicate hallucination/overconfidence risk and potential bias toward reporting violations.

5) Prompts (old vs current)
- Note: the separator lines in the current prompt are rendered with ASCII hyphens here to keep the file ASCII-only.

OLD PROMPT (GLOBAL_INSTRUCTIONS):
```
You are given a short road-traffic video clip. Perform a road-safety assessment using the whole clip.

Return exactly ONE JSON object and nothing else (no Markdown, no code fences, no backticks).

Hard constraints:
- Output MUST be valid JSON (RFC 8259). No trailing commas.
- Use ONLY the keys shown below. Do not add any other keys at any level.
- All fields must match the specified types exactly.
- If information is unknown/not visible, use null.
- For any field typed as string: it must be either a JSON string or null (NOT an array, NOT an object).
- If multiple items apply for a string field, put them in ONE string separated by "; " (semicolon + space).
- When asked for descriptions, be coincise, use one sentence.

Schema (types are strict):

{
  "answer": {
    "road_composition": {
      "lanes_number": <integer or null>,
      "traffic_direction": <string or null>,
      "traffic_lights": <string or null>,
      "pedestrian_crossings": <string or null>,
      "horizontal_signs": <string or null>,
      "vertical_signs": <string or null>,
      "other_infrastructure": <string or null>
    },
    "traffic_status": {
      "per_lane": [
        {
          "lane_id": <integer>,
          "description": <string>
        }
      ],
      "general_conditions": <string or null>
    },
    "pedestrians": {
      "locations": <string or null>,
      "actions": <string or null>,
      "interaction_with_traffic": <string or null>
    },
    "risks_or_violations": [
      {
        "actor": <string>,
        "type": <string>,
        "description": <string>
      }
    ]
  }
}

Return JSON now.
```

CURRENT PROMPT (PROMPT_JSON_DETAILED):
```
You are analyzing a sequence of frames extracted in temporal order from a road traffic video.

Your task is to produce a structured road-safety assessment in JSON format.

You must follow two independent layers:
(1) epistemic rules (what is visible vs what is uncertain)
(2) the output schema (what fields must exist)

Output ONLY valid JSON.
Do NOT include explanations, markdown, or extra text.

--------------------------------------------
EPISTEMIC RULES
--------------------------------------------

1. Visibility vs uncertainty
Each observable element must be classified as either:
- NOT VISIBLE in the frames
- VISIBLE (even if ambiguous)

Use:
- "visible": false only when the element is not visible at all.
- "visible": true when the element appears in the frames, even if unclear.

If "visible": true:
- You MUST provide a "value" (even if uncertain).
- You MUST provide a "confidence" in [0,1].

If something is visible but cannot be determined with certainty, use:
- "value": "unknown"
and assign a low confidence.

Do NOT use null for uncertainty.
Null is allowed only for entire structures that are logically not applicable (see Rule 3).

2. Estimation rule
When something is visible but ambiguous (e.g., lane count, markings, signs), choose the most plausible interpretation and lower the confidence.
Do not avoid making an estimate just because it is uncertain.

3. Lane -> traffic dependency
- If number_of_lanes.visible = true, you MUST output exactly one traffic_status entry per lane.
- If number_of_lanes.visible = false, then traffic_status MUST be null.

4. Events
- If no vehicle events are observed, output vehicle_events as an empty array.
- If no pedestrian events are observed, output pedestrian_events as an empty array.
- If multiple entities perform the same behavior, represent them as ONE event with a "count" field.

5. No hallucination
Do not invent objects, signs, lights, or events that are not supported by the frames.

--------------------------------------------
OUTPUT SCHEMA
--------------------------------------------

The JSON object must have exactly this structure.
Placeholders indicate types, not default values.

{
  "road_composition": {
    "number_of_lanes": {
      "visible": <boolean>,
      "value": <integer or "unknown">,
      "confidence": <number>
    },

    "lane_directions": {
      "visible": <boolean>,
      "value": "one_way | two_way | unknown",
      "confidence": <number>
    },

    "road_type": {
      "visible": <boolean>,
      "value": "urban | suburban | highway | pedestrian_zone | unknown",
      "confidence": <number>
    },

    "pedestrian_crossings": {
      "visible": <boolean>,
      "present": { "value": <boolean>, "confidence": <number> },
      "type": { "value": "zebra | traffic_light_controlled | other | unknown", "confidence": <number> }
    },

    "traffic_lights": {
      "visible": <boolean>,
      "present": { "value": <boolean>, "confidence": <number> },
      "visible_state": { "value": "red | yellow | green | unknown", "confidence": <number> }
    },

    "horizontal_signage": {
      "visible": <boolean>,
      "lane_markings": { "value": <boolean>, "confidence": <number> },
      "stop_lines": { "value": <boolean>, "confidence": <number> },
      "other_markings": { "value": <boolean>, "confidence": <number> }
    },

    "vertical_signage": {
      "visible": <boolean>,
      "speed_limit": { "value": <integer or "unknown">, "confidence": <number> },
      "warning_signs": { "value": <boolean>, "confidence": <number> },
      "prohibition_signs": { "value": <boolean>, "confidence": <number> }
    }
  },

  "traffic_status": <null or array of {
      "lane_id": <integer>,
      "status": { "value": "free | slow | congested | stopped", "confidence": <number> },
      "vehicle_density": { "value": "low | medium | high", "confidence": <number> }
  }>,

  "vehicle_events": [
    {
      "event_type": "speeding | red_light_violation | illegal_lane_change | wrong_direction | illegal_stop | other",
      "description": <string>,
      "involved_vehicle_type": "car | truck | motorcycle | bus | unknown",
      "risk_level": "low | medium | high",
      "confidence": <number>,
      "count": <integer>
    }
  ],

  "pedestrian_events": [
    {
      "behavior": "crossing_legally | jaywalking | waiting | standing_in_road | other",
      "location": "crosswalk | sidewalk | roadway | median | unknown",
      "interaction_with_vehicles": "none | near_miss | conflict",
      "risk_level": "low | medium | high",
      "confidence": <number>,
      "count": <integer>
    }
  ],

  "overall_risk_assessment": {
    "risk_level": { "value": "low | medium | high", "confidence": <number> },
    "main_risk_factors": <array of strings>
  }
}

Output MUST be valid JSON and respect all rules above.
```
